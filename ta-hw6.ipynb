{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federal University of Ceará\n",
    "# Teleinformatics Departament\n",
    "# Graduate Program in Teleinformatics Engeneering\n",
    "## TIP8419 - Tensor Algebra\n",
    "## Homework 6 - High Order Singular Value Decomposition (HOSVD) and Higher-Order Orthogonal Iteration (HOOI) Algorithm\n",
    "### Report and Simulation results\n",
    "\n",
    "- Ezequias Márcio - 497779\n",
    "\n",
    "To run this notebook properly, it is necessary Python3 installed alongside with the packages listed below:\n",
    "\n",
    "- `numpy 1.17.2`\n",
    "- `scipy 1.4.1`\n",
    "- `tdqm 4.36.1`\n",
    "- `bokeh 1.3.4`\n",
    "\n",
    "Make sure that the files `tensoralg.py` and `ta_simulations.py` are in the same directory as this notebook. In this files, it can be found the tensor algebra module functions and the code listings of the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the simulation module:\n",
    "from ta_simulations import *\n",
    "np.set_printoptions(4, linewidth=175)\n",
    "# Loading files:\n",
    "data1 = loadmat('files/hosvd_test.mat'); data2 = loadmat('files/hosvd_denoising.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "For a third-order tensor $\\mathbf{\\mathcal{X}} \\in \\mathbb{C}^{I \\times J \\times K}$ implement the truncated high-order singular value decomposition (HOSVD), using the following prototype function:\n",
    "\n",
    "\\begin{equation}\n",
    "    [\\mathbf{\\mathcal{S}},\\mathbf{U}^{(1)},\\mathbf{U}^{(2)},\\mathbf{U}^{(3)}] = \\text{hosvd}(\\mathbf{\\mathcal{X}})\n",
    "\\end{equation}\n",
    "\n",
    "### Solution: \n",
    "\n",
    "The functioning of the implemented routine is shown in the cell below where the third-order tensor  $\\mathbf{\\mathcal{X}}$  is randomly generated, and then it is applied the decomposition and calculated the Normalized Mean Square Error between the tensor and their reconstructed version for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor (3, 2, 4):\n",
      "[[[0.179 +0.7066j 0.6017+0.5289j 0.8895+0.6512j 0.5224+0.4758j]\n",
      "  [0.13  +0.8764j 0.7053+0.8471j 0.3777+0.5329j 0.6613+0.3432j]]\n",
      "\n",
      " [[0.7646+0.9806j 0.0269+0.6327j 0.1301+0.3044j 0.9962+0.568j ]\n",
      "  [0.8037+0.0694j 0.1189+0.0305j 0.8929+0.9995j 0.8164+0.5073j]]\n",
      "\n",
      " [[0.8056+0.9j    0.3744+0.6389j 0.4471+0.5578j 0.5534+0.4731j]\n",
      "  [0.4352+0.4452j 0.6607+0.3656j 0.8446+0.3734j 0.1227+0.0654j]]]\n",
      "\n",
      "Reconstructed Tensor (3, 2, 4):\n",
      "[[[0.179 +0.7066j 0.6017+0.5289j 0.8895+0.6512j 0.5224+0.4758j]\n",
      "  [0.13  +0.8764j 0.7053+0.8471j 0.3777+0.5329j 0.6613+0.3432j]]\n",
      "\n",
      " [[0.7646+0.9806j 0.0269+0.6327j 0.1301+0.3044j 0.9962+0.568j ]\n",
      "  [0.8037+0.0694j 0.1189+0.0305j 0.8929+0.9995j 0.8164+0.5073j]]\n",
      "\n",
      " [[0.8056+0.9j    0.3744+0.6389j 0.4471+0.5578j 0.5534+0.4731j]\n",
      "  [0.4352+0.4452j 0.6607+0.3656j 0.8446+0.3734j 0.1227+0.0654j]]]\n",
      "\n",
      "NMSE Result: 3.2312806742269546e-31\n"
     ]
    }
   ],
   "source": [
    "# Generate data and applying the decomposition:\n",
    "I, J, K = 2, 4, 3\n",
    "tensor = np.random.rand(K, I, J*2).view(np.complex_); core, matrices_u = tensoralg.hosvd(tensor)\n",
    "tensor_hat = tensoralg.m_mode_prod(core, matrices_u) # Reconstructing tensor\n",
    "nmse_tensor = norm_mse(tensor, tensor_hat) # Normalized Mean Square Error\n",
    "print(f'''Tensor {tensor.shape}:\\n{tensor}\\n\\nReconstructed Tensor {tensor.shape}:\\n{tensor}\\n\\nNMSE Result: {nmse_tensor}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by the result above, the small error indicates that the implemente HOSVD algorithm has a good performance for the multilinear rank approximation. Also, in the cell below is verified if the core tensor obtained with thos routine attends the properties of all-orthogonality and the order of the n-mode singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension I=2: [0. 0.]\n",
      "Dimension J=4: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Dimension K=3: [0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "N-th singular values (I, J, K):\n",
      "[3.9674 1.3286]\n",
      "[3.8328 1.2218 1.0643 0.4353]\n",
      "[3.855  1.4534 0.7293]\n"
     ]
    }
   ],
   "source": [
    "all_orth(core) # All orthogonality and ...\n",
    "nth_singular_val(core) # n-th singular values ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Using the file “hosvd_test.mat” to validate the implemented routine in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Problem 1 validation: Tensor X (5, 3, 4)\n",
      "\n",
      "Normalized Mean Square Errors:\n",
      "\n",
      "Tensor X_hat: 3.5036209766369374e-31\n",
      "\n",
      "Core tensor S: 1.5607066827251088\n",
      "\n",
      "U1: 0.0\n",
      "U2: 0.0005771204134077603\n",
      "U3: 0.04761713475835911\n"
     ]
    }
   ],
   "source": [
    "# Test data:\n",
    "X_test = data1['tenX'].transpose(2, 0, 1); S_test = data1['tenS'].transpose(2, 0, 1)\n",
    "U1_test = data1['U1']; U2_test = data1['U2']; U3_test = data1['U3']\n",
    "# Applying the decomposition and Reconstructing tensor X:\n",
    "S_hat, U_hat_list = tensoralg.hosvd(X_test); X_hat = tensoralg.m_mode_prod(S_hat, U_hat_list)\n",
    "# Normalized Mean Square Errors:\n",
    "nmse_x = norm_mse(X_test, X_hat); nmse_s = norm_mse(S_test, S_hat)\n",
    "nmse_u1 = norm_mse(U1_test, U_hat_list[0]); nmse_u2 =norm_mse(U2_test, U_hat_list[1]); nmse_u3 = norm_mse(U3_test, U_hat_list[2])\n",
    "print(f'''Data for Problem 1 validation: Tensor X {X_test.shape}\\n''')\n",
    "print(f'''Normalized Mean Square Errors:\\n\\nTensor X_hat: {nmse_x}\\n\\nCore tensor S: {nmse_s}\\n\\nU1: {nmse_u1}\\nU2: {nmse_u2}\\nU3: {nmse_u3}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by the result above, the implemented algorithm is working as expected, presenting a small error for the reconstructed tensor, and the difference betwen the core tensor provided and the matrices $\\mathbf{U}_n$ is due to the lack of uniqueness for the core tensor and these matrices obtained by the HOSVD algorithm.\n",
    "\n",
    "### HOOI Algorithm:\n",
    "\n",
    "The results of Problem 1 obtained using the implemented HOOI algorithm for the decomposition is shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1; Error: 4.664258731808323e-16\n",
      "Tensor (3, 2, 4):\n",
      "[[[0.179 +0.7066j 0.6017+0.5289j 0.8895+0.6512j 0.5224+0.4758j]\n",
      "  [0.13  +0.8764j 0.7053+0.8471j 0.3777+0.5329j 0.6613+0.3432j]]\n",
      "\n",
      " [[0.7646+0.9806j 0.0269+0.6327j 0.1301+0.3044j 0.9962+0.568j ]\n",
      "  [0.8037+0.0694j 0.1189+0.0305j 0.8929+0.9995j 0.8164+0.5073j]]\n",
      "\n",
      " [[0.8056+0.9j    0.3744+0.6389j 0.4471+0.5578j 0.5534+0.4731j]\n",
      "  [0.4352+0.4452j 0.6607+0.3656j 0.8446+0.3734j 0.1227+0.0654j]]]\n",
      "\n",
      "Reconstructed Tensor (3, 2, 4):\n",
      "[[[0.179 +0.7066j 0.6017+0.5289j 0.8895+0.6512j 0.5224+0.4758j]\n",
      "  [0.13  +0.8764j 0.7053+0.8471j 0.3777+0.5329j 0.6613+0.3432j]]\n",
      "\n",
      " [[0.7646+0.9806j 0.0269+0.6327j 0.1301+0.3044j 0.9962+0.568j ]\n",
      "  [0.8037+0.0694j 0.1189+0.0305j 0.8929+0.9995j 0.8164+0.5073j]]\n",
      "\n",
      " [[0.8056+0.9j    0.3744+0.6389j 0.4471+0.5578j 0.5534+0.4731j]\n",
      "  [0.4352+0.4452j 0.6607+0.3656j 0.8446+0.3734j 0.1227+0.0654j]]]\n",
      "\n",
      "NMSE Result HOOI: 2.175530951725019e-31\n",
      "\n",
      "All-orthogonality and n-th mode singular values:\n",
      "Dimension I=2: [0. 0.]\n",
      "Dimension J=4: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Dimension K=3: [0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "N-th singular values (I, J, K):\n",
      "[3.9674 1.3286]\n",
      "[3.8328 1.2218 1.0643 0.4353]\n",
      "[3.855  1.4534 0.7293]\n"
     ]
    }
   ],
   "source": [
    "core, matrices_u = tensoralg.hooi(tensor, verb=True); tensor_hat = tensoralg.m_mode_prod(core, matrices_u) # HOOI and Reconstruction\n",
    "nmse_tensor = norm_mse(tensor, tensor_hat) # Normalized Mean Square Error\n",
    "print(f'''Tensor {tensor.shape}:\\n{tensor}\\n\\nReconstructed Tensor {tensor.shape}:\\n{tensor}\\n\\nNMSE Result HOOI: {nmse_tensor}\\n\n",
    "All-orthogonality and n-th mode singular values:''')\n",
    "all_orth(core) # All orthogonality and ...\n",
    "nth_singular_val(core) # n-th singular values ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by the result above, the implemented HOOI algorithm gives a better aproximation in the squared norm sense as expected, conveging fast (1 iteration was required) due to the HOSVD initialization.\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "Consider the two third-order tensors  $\\mathbf{\\mathcal{X}} \\in \\mathbb{C}^{8 \\times 4 \\times 10}$ and $\\mathbf{\\mathcal{X}} \\in \\mathbb{C}^{5 \\times 5 \\times 5}$ provided in the data file “hosvd_denoising.mat”. By using your HOSVD prototype function, find a low multilinear rank approximation for these tensors, defined as $\\mathbf{\\mathcal{\\tilde{X}}} \\in \\mathbb{C}^{R_{1} \\times R_{2} \\times R_{3}}$  and $\\mathbf{\\mathcal{\\tilde{Y}}} \\in \\mathbb{C}^{P_{1} \\times P_{2} \\times P_{3}}$. Then, calculate the normalized mean square error (NMSE) between the original tensor and its approximation, i.e.:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{NMSE}(\\mathbf{\\mathcal{\\tilde{X}}}) = \\frac{||\\mathbf{\\mathcal{\\tilde{X}}} - \\mathbf{\\mathcal{X}}||^{2}_{F}}{||\\mathbf{\\mathcal{X}}||^{2}_{F}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{NMSE}(\\mathbf{\\mathcal{\\tilde{Y}}}) = \\frac{||\\mathbf{\\mathcal{\\tilde{Y}}} - \\mathbf{\\mathcal{Y}}||^{2}_{F}}{||\\mathbf{\\mathcal{Y}}||^{2}_{F}}\n",
    "\\end{equation}\n",
    "\n",
    "### Solution:\n",
    "\n",
    "First the profile of the 1-mode, 2-mode and 3-mode singular values of these tensors is shown in the cell below. They are obtained via HOSVD, and the shapes are in the Numpy's notation $(K, I, J)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor X (10, 8, 4):\n",
      "\n",
      "N-th singular values (I, J, K):\n",
      "[8.1751e+01 3.0525e+01 9.2473e-02 7.1115e-02 6.0448e-02 5.6937e-02 5.0975e-02 4.9795e-02]\n",
      "[77.1635 36.2239 18.6487  0.951 ]\n",
      "[7.6196e+01 3.2575e+01 2.0674e+01 1.4816e+01 1.0058e+01 6.3973e-02 5.9474e-02 5.7325e-02 3.8697e-02 3.5704e-02]\n",
      "\n",
      "Tensor Y (5, 5, 5):\n",
      "\n",
      "N-th singular values (I, J, K):\n",
      "[6.9484 0.5317 0.4889 0.4173 0.3624]\n",
      "[6.9479 0.5884 0.4831 0.4045 0.3021]\n",
      "[6.9415 0.5561 0.5144 0.4414 0.3933]\n"
     ]
    }
   ],
   "source": [
    "# Loading data:\n",
    "tensor_x = data2['tenX_noise'].transpose(2, 0, 1); tensor_y = data2['tenY_noise'].transpose(2, 0, 1)\n",
    "core_x, _ = tensoralg.hosvd(tensor_x); core_y, _ = tensoralg.hosvd(tensor_y); \n",
    "print(f'Tensor X {tensor_x.shape}:')\n",
    "nth_singular_val(core_x)\n",
    "print(f'\\nTensor Y {tensor_y.shape}:')\n",
    "nth_singular_val(core_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the two tensors are full rank, so to ilustrate the low multilinear rank approximation it will be chosen $R_{1}, R_{2}, R_{3} = \n",
    "6, 3, 7$ and $P_{1}, P_{2}, P_{3} = 4, 4, 3$. The NMSE results are shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE X: 0.00011976217163409791 \n",
      "NMSE Y: 0.00991106315233519\n"
     ]
    }
   ],
   "source": [
    "# Tuncated HOSVD:\n",
    "target_x, Ux = tensoralg.hosvd(tensor_x, [6, 3, 7]); target_y, Uy = tensoralg.hosvd(tensor_y, [4, 4, 3])\n",
    "# Reconstruction:\n",
    "rec_tensor_x = tensoralg.m_mode_prod(target_x, Ux); rec_tensor_y = tensoralg.m_mode_prod(target_y, Uy)\n",
    "nmse_x = norm_mse(tensor_x, rec_tensor_x); nmse_y = norm_mse(tensor_y, rec_tensor_y)\n",
    "print(f'''NMSE X: {nmse_x} \\nNMSE Y: {nmse_y}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE X: 0.00011955278395507484 \n",
      "NMSE Y: 0.00991106315233519\n"
     ]
    }
   ],
   "source": [
    "# Tuncated HOOi with HOSVD initialization:\n",
    "target_x, Ux = tensoralg.hooi(tensor_x, rank_list=[6, 3, 7]); target_y, Uy = tensoralg.hosvd(tensor_y, rank_list=[4, 4, 3])\n",
    "# Reconstruction:\n",
    "rec_tensor_x = tensoralg.m_mode_prod(target_x, Ux); rec_tensor_y = tensoralg.m_mode_prod(target_y, Uy)\n",
    "nmse_x = norm_mse(tensor_x, rec_tensor_x); nmse_y = norm_mse(tensor_y, rec_tensor_y)\n",
    "print(f'''NMSE X: {nmse_x} \\nNMSE Y: {nmse_y}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the HOSVD and the HOOI multilinear rank approximation of these two tensors gives a good aproximation presenting an error $\\approx 1\\%$ for the considered dimensions."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
